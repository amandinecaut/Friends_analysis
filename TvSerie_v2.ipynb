{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c1e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import euclidean\n",
    "from IPython.core.pylabtools import figsize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.linear_model as skl_lm\n",
    "import matplotlib.patches as mpatches\n",
    "import sklearn.neighbors as skl_nb\n",
    "from sklearn.cluster import KMeans\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "from numpy import argmax\n",
    "from numpy import array\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d27185a",
   "metadata": {},
   "source": [
    "# The Big Bang Theory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('C:/Users/amaca253/Desktop/Friends-Friends-Language-Analysis/BBT/data_300pca.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c31c6",
   "metadata": {},
   "source": [
    "## Part1: PCA study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef2af9",
   "metadata": {},
   "source": [
    "### PCA1 vs PCA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10\n",
    "X = df.loc[:,'PCA1':'PCA2']\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=num_clusters, \n",
    "    init='k-means++', \n",
    "    max_iter=100, \n",
    "    n_init=50)\n",
    "\n",
    "\n",
    "label = kmeans.fit_predict(X)\n",
    "df['Cluster']= label\n",
    "df2 = X.values\n",
    "\n",
    "closest_pt_idx = []\n",
    "for iclust in range(kmeans.n_clusters):\n",
    "    cluster_pts = df2[kmeans.labels_ == iclust]\n",
    "    cluster_pts_indices = np.where(kmeans.labels_ == iclust)[0]\n",
    "    cluster_cen = kmeans.cluster_centers_[iclust]\n",
    "    min_idx = np.argmin([euclidean(df2[idx], cluster_cen) for idx in cluster_pts_indices])\n",
    "    closest_pt_idx.append(cluster_pts_indices[min_idx])\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "centroid_list = []\n",
    "for i in np.arange(len(centroids)):\n",
    "    liste= [i, centroids[i,0], centroids[i,1]]\n",
    "    centroid_list.append(liste)\n",
    "\n",
    "\n",
    "centroid_list = sorted(centroid_list, key=itemgetter(1))\n",
    "\n",
    "\n",
    "u_labels = np.unique(label)\n",
    "text = [df['Said'][closest_pt_idx[i]] for i in range(num_clusters)]\n",
    "text2 = [ '\\n'.join(wrap(l, 40)) for l in text]\n",
    "\n",
    "\n",
    "colors = sns.color_palette('tab20', 10)\n",
    "ind_col_map = {x:y for x, y in zip(df['Cluster'].unique(),colors)}\n",
    "ind_col_map = dict(sorted(ind_col_map.items()))\n",
    "\n",
    "key_order = [i[0] for i in centroid_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (13,9))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in u_labels:\n",
    "    ax.scatter(df2[label == i , 0] , df2[label == i , 1] ,color=ind_col_map[i],  label = i, alpha= 0.25)\n",
    "ax.scatter(centroids[:,0] , centroids[:,1] , s = 20, color = 'k')\n",
    "\n",
    "legend_list = []\n",
    "for key in key_order:\n",
    "    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "    \n",
    "plt.xlim(-11.5,13)\n",
    "plt.ylim(-10,14) \n",
    "\n",
    "ax.legend(title='Average phrase',bbox_to_anchor=(1.02, 1),handles=legend_list, loc='upper left',borderaxespad=0, fontsize=12, title_fontsize=14)\n",
    "x_text = 'PCA1: Short phrase to phrase that include \\\"Sheldon \\\"' #for pca1\n",
    "plt.xlabel(x_text, ha='center', labelpad=35, fontsize=14)\n",
    "an1 = plt.annotate('+', xy=(0.02, -0.08), xycoords='axes fraction', xytext=(1, -0.08), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an2 = plt.annotate('-', xy=(-0.02, -0.08), xycoords=an1, fontsize=15)\n",
    "\n",
    "\n",
    "y_text = 'PCA2: Long phrase about a female character \\n to short phrase about \\\"Sheldon\\\" ' # for pca2\n",
    "plt.ylabel(y_text, ha='center', labelpad=35, fontsize=14)\n",
    "an3 = plt.annotate('+', xy=(-0.06, -0.02), xycoords='axes fraction', xytext=(-0.06, 1), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an4 = plt.annotate('-', xy=(-0.06, -0.04), xycoords=an3, fontsize=15)\n",
    "\n",
    "#plt.savefig('PCA1_2.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da3cb0",
   "metadata": {},
   "source": [
    "#### Average Position (of PCA1 vs PCA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a25b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheldon =df[df['Person'].str.contains('Sheldon')]\n",
    "sheldon_mean_pca1_index = sheldon['PCA1'].mean()\n",
    "sheldon_mean_pca2_index = sheldon['PCA2'].mean()\n",
    "\n",
    "leonard =df[df['Person'].str.contains('Leonard')]\n",
    "leonard_mean_pca1_index = leonard['PCA1'].mean()\n",
    "leonard_mean_pca2_index = leonard['PCA2'].mean()\n",
    "\n",
    "penny =df[df['Person'].str.contains('Penny')]\n",
    "penny_mean_pca1_index = penny['PCA1'].mean()\n",
    "penny_mean_pca2_index = penny['PCA2'].mean()\n",
    "\n",
    "howard =df[df['Person'].str.contains('Howard')]\n",
    "howard_mean_pca1_index = howard['PCA1'].mean()\n",
    "howard_mean_pca2_index = howard['PCA2'].mean()\n",
    "\n",
    "raj =df[df['Person'].str.contains('Raj')]\n",
    "raj_mean_pca1_index = raj['PCA1'].mean()\n",
    "raj_mean_pca2_index = raj['PCA2'].mean()\n",
    "\n",
    "bernadette =df[df['Person'].str.contains('Bernadette')]\n",
    "bernadette_mean_pca1_index = bernadette['PCA1'].mean()\n",
    "bernadette_mean_pca2_index = bernadette['PCA2'].mean()\n",
    "\n",
    "amy =df[df['Person'].str.contains('Amy')]\n",
    "amy_mean_pca1_index = amy['PCA1'].mean()\n",
    "amy_mean_pca2_index = amy['PCA2'].mean()\n",
    "\n",
    "text = [df['Said'][closest_pt_idx[i]] for i in range(num_clusters)]\n",
    "text2 = [ '\\n'.join(wrap(l, 40)) for l in text]\n",
    "\n",
    "colors = sns.color_palette('tab20', 10)\n",
    "ind_col_map = {x:y for x, y in zip(df['Cluster'].unique(),colors)}\n",
    "ind_col_map = dict(sorted(ind_col_map.items()))\n",
    "\n",
    "key_order = [i[0] for i in centroid_list]\n",
    "\n",
    "df2 = X.values\n",
    "\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for i in u_labels:\n",
    "    ax.scatter(df2[label == i , 0] , df2[label == i , 1] ,color=ind_col_map[i],  label = i, alpha= 0.25)\n",
    "\n",
    "\n",
    "\n",
    "legend_list = []\n",
    "for key in key_order:\n",
    "    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "\n",
    "#ax.legend(title='Average phrase',bbox_to_anchor=(1.02, 1),handles=legend_list, loc='upper left',borderaxespad=0, fontsize=11, title_fontsize=13)\n",
    "\n",
    "\n",
    "plt.annotate('Sheldon', (sheldon_mean_pca1_index,sheldon_mean_pca2_index), xytext=(10,-10),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"), fontsize=16)\n",
    "\n",
    "plt.annotate('Leonard', (leonard_mean_pca1_index, leonard_mean_pca2_index), xytext=(10,10),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Penny', (penny_mean_pca1_index, penny_mean_pca2_index), xytext=(10,10),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Howard', (howard_mean_pca1_index ,howard_mean_pca2_index ), xytext=(-70,2),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Raj', (raj_mean_pca1_index,raj_mean_pca2_index), xytext=(10,9),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Bernadette', (bernadette_mean_pca1_index, bernadette_mean_pca2_index), xytext=(10,11),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Amy', (amy_mean_pca1_index, amy_mean_pca2_index),xytext=(10,10),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.xlim(-1,2)\n",
    "plt.ylim(-0.6,0.75) \n",
    "\n",
    "plt.title('Average position for each character')\n",
    "\n",
    "plt.xlabel(x_text, ha='center', labelpad=20, fontsize=14)\n",
    "\n",
    "plt.ylabel(y_text, ha='center', labelpad=20, fontsize=14)\n",
    "\n",
    "plt.savefig('average position.png',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdbfdb9",
   "metadata": {},
   "source": [
    "### PCA3 vs PCA4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10\n",
    "X = df.loc[:,'PCA3':'PCA4']\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=num_clusters, \n",
    "    init='k-means++', \n",
    "    max_iter=100, \n",
    "    n_init=50)\n",
    "\n",
    "\n",
    "label = kmeans.fit_predict(X)\n",
    "df['Cluster']= label\n",
    "df2 = X.values\n",
    "\n",
    "closest_pt_idx = []\n",
    "for iclust in range(kmeans.n_clusters):\n",
    "    cluster_pts = df2[kmeans.labels_ == iclust]\n",
    "    cluster_pts_indices = np.where(kmeans.labels_ == iclust)[0]\n",
    "    cluster_cen = kmeans.cluster_centers_[iclust]\n",
    "    min_idx = np.argmin([euclidean(df2[idx], cluster_cen) for idx in cluster_pts_indices])\n",
    "    closest_pt_idx.append(cluster_pts_indices[min_idx])\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "centroid_list = []\n",
    "for i in np.arange(len(centroids)):\n",
    "    liste= [i, centroids[i,0], centroids[i,1]]\n",
    "    centroid_list.append(liste)\n",
    "\n",
    "\n",
    "centroid_list = sorted(centroid_list, key=itemgetter(1))\n",
    "\n",
    "\n",
    "u_labels = np.unique(label)\n",
    "text = [df['Said'][closest_pt_idx[i]] for i in range(num_clusters)]\n",
    "text2 = [ '\\n'.join(wrap(l, 40)) for l in text]\n",
    "\n",
    "\n",
    "colors = sns.color_palette('tab20', 10)\n",
    "ind_col_map = {x:y for x, y in zip(df['Cluster'].unique(),colors)}\n",
    "ind_col_map = dict(sorted(ind_col_map.items()))\n",
    "\n",
    "key_order = [i[0] for i in centroid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ead66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (13,9))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in u_labels:\n",
    "    ax.scatter(df2[label == i , 0] , df2[label == i , 1] ,color=ind_col_map[i],  label = i, alpha= 0.25)\n",
    "ax.scatter(centroids[:,0] , centroids[:,1] , s = 20, color = 'k')\n",
    "\n",
    "legend_list = []\n",
    "for key in key_order:\n",
    "    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "    \n",
    "plt.xlim(-11.5,13)\n",
    "plt.ylim(-10,14) \n",
    "\n",
    "ax.legend(title='Average phrase',bbox_to_anchor=(1.02, 1),handles=legend_list, loc='upper left',borderaxespad=0, fontsize=12, title_fontsize=14)\n",
    "\n",
    "x_text = 'PCA3: Phrase that question a premise to phrase with a first person future action'\n",
    "plt.xlabel(x_text, ha='center', labelpad=35, fontsize=14)\n",
    "an1 = plt.annotate('+', xy=(0.02, -0.08), xycoords='axes fraction', xytext=(1, -0.08), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an2 = plt.annotate('-', xy=(-0.02, -0.08), xycoords=an1, fontsize=15)\n",
    "\n",
    "y_text = 'PCA4: Phrase about relationship to phrase related to food'\n",
    "plt.ylabel(y_text, ha='center', labelpad=35, fontsize=14)\n",
    "an3 = plt.annotate('+', xy=(-0.06, -0.02), xycoords='axes fraction', xytext=(-0.06, 1), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an4 = plt.annotate('-', xy=(-0.06, -0.04), xycoords=an3, fontsize=15)\n",
    "\n",
    "plt.savefig('PCA3_4.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a6c9f",
   "metadata": {},
   "source": [
    "### PCA5 vs PCA6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28152ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10\n",
    "X = df.loc[:,'PCA5':'PCA6']\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=num_clusters, \n",
    "    init='k-means++', \n",
    "    max_iter=100, \n",
    "    n_init=50)\n",
    "\n",
    "\n",
    "label = kmeans.fit_predict(X)\n",
    "df['Cluster']= label\n",
    "df2 = X.values\n",
    "\n",
    "closest_pt_idx = []\n",
    "for iclust in range(kmeans.n_clusters):\n",
    "\n",
    "    cluster_pts = df2[kmeans.labels_ == iclust]\n",
    "    cluster_pts_indices = np.where(kmeans.labels_ == iclust)[0]\n",
    "    cluster_cen = kmeans.cluster_centers_[iclust]\n",
    "    min_idx = np.argmin([euclidean(df2[idx], cluster_cen) for idx in cluster_pts_indices])\n",
    "    closest_pt_idx.append(cluster_pts_indices[min_idx])\n",
    "    \n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "centroid_list = []\n",
    "for i in np.arange(len(centroids)):\n",
    "    liste= [i, centroids[i,0], centroids[i,1]]\n",
    "    centroid_list.append(liste)\n",
    "\n",
    "\n",
    "centroid_list = sorted(centroid_list, key=itemgetter(1))\n",
    "\n",
    "\n",
    "u_labels = np.unique(label)\n",
    "text = [df['Said'][closest_pt_idx[i]] for i in range(num_clusters)]\n",
    "text2 = [ '\\n'.join(wrap(l, 40)) for l in text]\n",
    "\n",
    "\n",
    "colors = sns.color_palette('tab20', 10)\n",
    "ind_col_map = {x:y for x, y in zip(df['Cluster'].unique(),colors)}\n",
    "ind_col_map = dict(sorted(ind_col_map.items()))\n",
    "\n",
    "key_order = [i[0] for i in centroid_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937875c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (13,9))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in u_labels:\n",
    "    ax.scatter(df2[label == i , 0] , df2[label == i , 1] ,color=ind_col_map[i],  label = i, alpha= 0.25)\n",
    "ax.scatter(centroids[:,0] , centroids[:,1] , s = 20, color = 'k')\n",
    "\n",
    "legend_list = []\n",
    "for key in key_order:\n",
    "    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "    \n",
    "\n",
    "        \n",
    "plt.xlim(-11.5,13)\n",
    "plt.ylim(-10,14) \n",
    "\n",
    "ax.legend(title='Average phrase',bbox_to_anchor=(1.02, 1),handles=legend_list, loc='upper left',borderaxespad=0, fontsize=12, title_fontsize=14)\n",
    "\n",
    "x_text = 'PCA5: Discussion with often a negation to short question about a woman'\n",
    "plt.xlabel(x_text, ha='center', labelpad=35, fontsize=14)\n",
    "an1 = plt.annotate('+', xy=(0.02, -0.08), xycoords='axes fraction', xytext=(1, -0.08), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an2 = plt.annotate('-', xy=(-0.02, -0.08), xycoords=an1, fontsize=15)\n",
    "\n",
    "y_text = 'PCA6: Phrase with an apology to phrase with affirmative statement '\n",
    "plt.ylabel(y_text, ha='center', labelpad=35, fontsize=14)\n",
    "an3 = plt.annotate('+', xy=(-0.06, -0.02), xycoords='axes fraction', xytext=(-0.06, 1), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an4 = plt.annotate('-', xy=(-0.06, -0.04), xycoords=an3, fontsize=15)\n",
    "\n",
    "plt.savefig('PCA5_6.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8929a3aa",
   "metadata": {},
   "source": [
    "## Part2: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84aa75",
   "metadata": {},
   "source": [
    "### Roc-au-score and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e28e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def logistic_function(dataset, number_pca):\n",
    "    pca = 'PCA'+str(i)\n",
    "    X = df.loc[:,'PCA1':pca]\n",
    "    X = scaled(X)\n",
    "    y = integer_encoded\n",
    "    y = np.squeeze(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state = 0)\n",
    "    y_train, y_test =  np.squeeze(y_train),  np.squeeze(y_test)\n",
    "\n",
    "    model = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_return = roc_auc_score(y_test, model.decision_function(X_test), multi_class='ovr')\n",
    "    return roc_return\n",
    "\n",
    "\n",
    "def logistic_function_accuracy(dataset, number_pca):\n",
    "    pca = 'PCA'+str(i)\n",
    "    X = df.loc[:,'PCA1':pca]\n",
    "    X = scaled(X)\n",
    "    y = integer_encoded\n",
    "    y = np.squeeze(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state = 0)\n",
    "    y_train, y_test =  np.squeeze(y_train),  np.squeeze(y_test)\n",
    "\n",
    "    model = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def scaled(X):\n",
    "    stand = X.std(axis=0)\n",
    "    min_col = X.min(axis=0)\n",
    "    X = X.values\n",
    "    min_col = X.min(axis=1)\n",
    "    for pca in range(len(X[0,:])):\n",
    "        for row in range(len(X[:,0])):\n",
    "            X[row,pca] = (X[row,pca]-min_col[pca])/stand[pca]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0148278",
   "metadata": {},
   "source": [
    "#### Creation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sheldon =  df.loc[df['Person']== 'Sheldon']\n",
    "#Leonard = df.loc[df['Person']== 'Leonard']\n",
    "#df = pd.concat([Sheldon, Leonard], ignore_index=True)\n",
    "\n",
    "Penny = df.loc[df['Person']== 'Penny']\n",
    "df = pd.concat([Sheldon, Penny], ignore_index=True)\n",
    "\n",
    "print(df.pivot_table(index = ['Person'], aggfunc ='size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c24119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = df['Person']\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print('integer_encoded: ',integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58f31b",
   "metadata": {},
   "source": [
    "#### ROC-AU-SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for i in range(2,301,1):\n",
    "    print('process until PCA',i)\n",
    "    roc.append(logistic_function(df, i))\n",
    "    print('done')\n",
    "\n",
    "np.save('array_Ross_Phoebe.npy', roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703aaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_SP = np.load('array_Sheldon_Penny.npy')\n",
    "array_SL = np.load('array_Sheldon_Leonard.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2,301)\n",
    "y1 = np.asarray(array_SP)\n",
    "y2 = np.asarray(array_SL)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.ylim(0.51,0.8) \n",
    "line1, = ax.plot(x, y1, '#9467bd', label='Sheldon vs Penny')\n",
    "line2, = ax.plot(x, y2, '#17becf', label='Sheldon vs Leonard')\n",
    "ax.legend(handles=[line1, line2], loc = 'lower right')\n",
    "plt.xlabel('Number of PCA')\n",
    "plt.ylabel('AUC')\n",
    "plt.savefig('TBBT_auc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ebcc4",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147cd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(2,301,1):\n",
    "    print('process until PCA',i)\n",
    "    acc.append(logistic_function_accuracy(df, i))\n",
    "    print('done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('accuracy_Sheldon_Penny.npy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_SP = np.load('accuracy_Sheldon_Penny.npy')\n",
    "accuracy_SL = np.load('accuracy_Sheldon_Leonard.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed848d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2,301)\n",
    "y1 = np.asarray(accuracy_SP)\n",
    "y2 = np.asarray(accuracy_SL)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.ylim(0.51,0.8) \n",
    "line1, = ax.plot(x, y1, '#9467bd', label='Sheldon vs Penny')\n",
    "line2, = ax.plot(x, y2, '#17becf', label='Sheldon vs Leonard')\n",
    "ax.legend(handles=[line1, line2], loc = 'lower right')\n",
    "plt.xlabel('Number of PCA')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('TBBT_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a95f4",
   "metadata": {},
   "source": [
    "## Part3: Heat table and graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262da632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Creation of the binome\n",
    "personnes = ['Amy','Penny','Bernadette','Sheldon', 'Leonard', 'Raj', 'Howard']\n",
    "couples = list(itertools.combinations(personnes, 2))\n",
    "\n",
    "for couple in couples:\n",
    "    print(couple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, perso1, perso2):\n",
    "    character1 =  dataset.loc[dataset['Person']== perso1]\n",
    "    character2 =  dataset.loc[dataset['Person']== perso2]\n",
    "    df = pd.concat([character1, character2], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "roc =[]\n",
    "coef_matrix = np.zeros((len(couples),300))\n",
    "model_intercept = np.zeros(len(couples))\n",
    "i=0\n",
    "for couple in couples:\n",
    "    print(str(couple[0]), str(couple[1]))\n",
    "    df_t = create_dataset(df, str(couple[0]), str(couple[1]))\n",
    "\n",
    "    data = df_t['Person']\n",
    "    values = array(data)\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    y = integer_encoded\n",
    "    y = np.squeeze(y)\n",
    "    \n",
    "    X = df_t.loc[:,'PCA1':'PCA300']\n",
    "    stand = X.std(axis=0)\n",
    "    mean_col = X.mean(axis=0)\n",
    "    X = X.values\n",
    "\n",
    "    for pca in range(len(X[0,:])):\n",
    "        for row in range(len(X[:,0])):\n",
    "            X[row,pca] = (X[row,pca]-mean_col[pca])/stand[pca]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state = 0)\n",
    "    y_train, y_test =  np.squeeze(y_train),  np.squeeze(y_test)\n",
    "\n",
    "\n",
    "    model = LogisticRegression(solver='lbfgs').fit(X_train, y_train)\n",
    "\n",
    "    coef = model.coef_\n",
    "    coef_matrix[i]= coef\n",
    "    intercept=model.intercept_\n",
    "    model_intercept[i] = intercept[0]\n",
    "    classes=model.classes_\n",
    "    \n",
    "    #AUC\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_score = roc_auc_score(y_test, model.decision_function(X_test), multi_class='ovr')\n",
    "    temp = [str(couple[0]), str(couple[1]), roc_score]\n",
    "    roc.append(temp)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0973d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(roc, key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32838017",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for couple in couples:\n",
    "    temp = str(couple[0])+ ' and ' +str(couple[1])\n",
    "    data.append(temp)\n",
    "column_names = [f'PCA{i}' for i in range(1, 301)]\n",
    "df_matrix = pd.DataFrame(coef_matrix, columns=column_names)\n",
    "df_matrix['Pairs'] = data\n",
    "#df_matrix.to_pickle('C:/Users/amaca253/Desktop/Friends-Friends-Language-Analysis/BBT/coef_matrix_TBBT_solverlbfgs_unbalance.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a221d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = pd.read_pickle('C:/Users/amaca253/Desktop/Friends-Friends-Language-Analysis/BBT/coef_matrix_TBBT_solverlbfgs_unbalance.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''Here we would like to create a dataset such that we read each row\n",
    " will take the absolute value of the values and save the 10st values in a \n",
    " matrix, and the values of the te corresponding pca in a list'''\n",
    "df_subset = df_matrix.loc[:, 'PCA1':'PCA300']\n",
    "data = np.zeros((len(df_subset),10))\n",
    "\n",
    "text=[]\n",
    "for row in np.arange(len(df_matrix)):\n",
    "    selected_row = np.abs(df_subset.iloc[row])\n",
    "    top_10_columns = selected_row.nlargest(10)\n",
    "    data[row] =df_subset.loc[row][top_10_columns.index]\n",
    "    text.append(top_10_columns.index)\n",
    "\n",
    "\n",
    "column_names = [f'Column{i}' for i in range(1, 11)]\n",
    "df2 = pd.DataFrame(data, columns=column_names)\n",
    "df2['Pairs']= df_matrix['Pairs']\n",
    "\n",
    "\n",
    "# Here we want to sort the value of the 1st column\n",
    "df2 = df2.sort_values('Column1',ignore_index=True)\n",
    "\n",
    "data2 = df2.loc[:, 'Column1':'Column10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6dd690",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for i in np.arange(len(data)):\n",
    "    list_10 = []\n",
    "    for j in np.arange(len(data[0,:])):\n",
    "        list_temp = [data[i,j], text[i][j]] # we associate each cell to the corresponding PCA index before the sorting\n",
    "        list_10.append(list_temp)\n",
    "    data_list.append(list_10)\n",
    "\n",
    "\n",
    "sort_list = sorted(data_list, key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f59b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10, 6)) \n",
    "cmap= sns.diverging_palette(220, 20, as_cmap=True)\n",
    "maximum = data2['Column1'].abs().max()\n",
    "heatmap = sns.heatmap(data2, yticklabels=df2['Pairs'], xticklabels=[], linewidths=.5, ax=ax, cmap=cmap, vmin=-maximum, vmax=maximum)\n",
    "\n",
    "# Annotate each cell with the corresponding PCA label\n",
    "for i in range(len(df_subset)):\n",
    "    for j in range(10):\n",
    "        cell_label = sort_list[i][j][1]\n",
    "        ax.text(j + 0.5, i + 0.5, cell_label, ha='center', va='center', fontsize=8, color= 'white', fontweight = 'bold')\n",
    "#plt.savefig('heatmap_friends_abs_top10.png',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80641795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_names(names):\n",
    "    name_list = names.split(\" and \")\n",
    "    name_list = [name.strip() for name in name_list]\n",
    "    return name_list\n",
    "\n",
    "\n",
    "pair = []\n",
    "for i in np.arange(len(df2)):\n",
    "        couple = df2['Pairs'][i]\n",
    "        couple = split_names(couple)\n",
    "        temp = (couple[0], couple[1])\n",
    "        temp = 'P('+ str(couple[0])+ '|' + str(couple[0]) + ' or ' + str(couple[1]) + ')' \n",
    "        pair.append(temp)\n",
    "        print(temp)\n",
    "\n",
    "        \n",
    "df2['Pairs'] = pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6)) \n",
    "cmap= sns.diverging_palette(220, 20, as_cmap=True)\n",
    "maximum = data2['Column1'].abs().max()\n",
    "heatmap = sns.heatmap(data2, yticklabels=df2['Pairs'], xticklabels=[], linewidths=.5, ax=ax, cmap=cmap, vmin=-maximum, vmax=maximum)\n",
    "\n",
    "# Annotate each cell with the corresponding PCA label\n",
    "for i in range(len(df_subset)):\n",
    "    for j in range(10):\n",
    "        cell_label = sort_list[i][j][1]\n",
    "        ax.text(j + 0.5, i + 0.5, cell_label, ha='center', va='center', fontsize=8, color= 'white', fontweight = 'bold')\n",
    "plt.savefig('heatmap_Friends_abs_top10_2.png',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460415d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurrences(text_list):\n",
    "    counts = {}\n",
    "    for item in text_list:\n",
    "        if item in counts:\n",
    "            counts[item] += 1\n",
    "        else:\n",
    "            counts[item] = 1\n",
    "    return counts\n",
    "\n",
    "list_pca = []\n",
    "for i in range(len(df_subset)):\n",
    "    for j in range(10):\n",
    "        list_pca.append(sort_list[i][j][1])\n",
    "\n",
    "result = count_occurrences(list_pca)\n",
    "result = dict(sorted(result.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "for item, count in result.items():\n",
    "    print(f\"{item}: {count} occurrence(s)\")\n",
    "    \n",
    "for pca in list_pca:\n",
    "    print('\\subsection{',pca,'}')\n",
    "    \n",
    "    print('top values')\n",
    "    print('\\ begin{dialogue}')\n",
    "    x = df.nlargest(20,pca)\n",
    "    for i in range(len(x)):\n",
    "        print('\\speak{',x.iloc[i]['Person'],'}',x.iloc[i]['Said'])\n",
    "    print('\\end{dialogue}')\n",
    "    print()\n",
    "    \n",
    "    print('lowest values')\n",
    "    print('\\ begin{dialogue}')\n",
    "    x = df.nsmallest(20,pca)\n",
    "    for i in range(len(x)):\n",
    "        print('\\speak{',x.iloc[i]['Person'],'}',x.iloc[i]['Said'])\n",
    "    print('\\end{dialogue}')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d00c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def split_names(names):\n",
    "    name_list = names.split(\" and \")\n",
    "    name_list = [name.strip() for name in name_list]\n",
    "    return name_list\n",
    "\n",
    "\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "node = personnes\n",
    "G.add_nodes_from(node)\n",
    "\n",
    "coefficients={}\n",
    "edges = []\n",
    "for i in np.arange(len(df_matrix)):\n",
    "    coeff = df_matrix['PCA19'][i] #9 for friends and 19 for TBBT\n",
    "    print(coeff)\n",
    "    if np.abs(coeff) <= 0.1:\n",
    "        i+=1\n",
    "    else:\n",
    "        couple = split_names(df_matrix['Pairs'][i])\n",
    "        temp = (couple[0], couple[1], coeff )\n",
    "        edges.append(temp)\n",
    "\n",
    "\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# Create lists of edges and labels for positive and negative weights\n",
    "positive_edges = [(u, v) for u, v, d in G.edges(data=True) if d['weight'] >= 0]\n",
    "negative_edges = [(u, v) for u, v, d in G.edges(data=True) if d['weight'] < 0]\n",
    "edge_labels = {(u, v): f\"{w:.2f}\" if w >= 0 else f\"{-w:.2f}\" for (u, v, w) in G.edges(data='weight')}\n",
    "\n",
    "# Draw the graph\n",
    "fig, ax = plt.subplots(figsize=(10, 8))  # Adjust the size of the plot\n",
    "pos = nx.spring_layout(G, k=3)\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, edgelist=positive_edges, node_size=2500, node_color=\"skyblue\", \n",
    "        font_size=9, arrows=True, arrowstyle= '-|>')\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, edgelist=negative_edges,node_size=2500, node_color=\"skyblue\", \n",
    "        font_size=9, arrows=True, arrowstyle= '<|-')\n",
    "        \n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "#plt.savefig(\"graphTBBT.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1757da68",
   "metadata": {},
   "source": [
    "# Friends analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654769be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('C:/Users/amaca253/Desktop/Friends-Friends-Language-Analysis/BBT/data_300pca_friends2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097778",
   "metadata": {},
   "source": [
    "## Part1: PCA study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588d48f",
   "metadata": {},
   "source": [
    "### PCA1 vs PCA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b481392",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10\n",
    "X = df.loc[:,'PCA1':'PCA2']\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=num_clusters, \n",
    "    init='k-means++', \n",
    "    max_iter=100, \n",
    "    n_init=50)\n",
    "\n",
    "\n",
    "label = kmeans.fit_predict(X)\n",
    "df['Cluster']= label\n",
    "df2 = X.values\n",
    "\n",
    "closest_pt_idx = []\n",
    "for iclust in range(kmeans.n_clusters):\n",
    "    cluster_pts = df2[kmeans.labels_ == iclust]\n",
    "    cluster_pts_indices = np.where(kmeans.labels_ == iclust)[0]\n",
    "    cluster_cen = kmeans.cluster_centers_[iclust]\n",
    "    min_idx = np.argmin([euclidean(df2[idx], cluster_cen) for idx in cluster_pts_indices])\n",
    "    closest_pt_idx.append(cluster_pts_indices[min_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "centroid_list = []\n",
    "for i in np.arange(len(centroids)):\n",
    "    liste= [i, centroids[i,0], centroids[i,1]]\n",
    "    centroid_list.append(liste)\n",
    "\n",
    "\n",
    "centroid_list = sorted(centroid_list, key=itemgetter(1))\n",
    "\n",
    "\n",
    "u_labels = np.unique(label)\n",
    "text = [df['Said'][closest_pt_idx[i]] for i in range(num_clusters)]\n",
    "text2 = [ '\\n'.join(wrap(l, 40)) for l in text]\n",
    "\n",
    "\n",
    "colors = sns.color_palette('tab20', 10)\n",
    "ind_col_map = {x:y for x, y in zip(df['Cluster'].unique(),colors)}\n",
    "ind_col_map = dict(sorted(ind_col_map.items()))\n",
    "\n",
    "key_order = [i[0] for i in centroid_list]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize= (13,9))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in u_labels:\n",
    "    ax.scatter(df2[label == i , 0] , df2[label == i , 1] ,color=ind_col_map[i],  label = i, alpha= 0.25)\n",
    "ax.scatter(centroids[:,0] , centroids[:,1] , s = 20, color = 'k')\n",
    "\n",
    "legend_list = []\n",
    "for key in key_order:\n",
    "    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "    \n",
    "plt.xlim(-10,13)\n",
    "plt.ylim(-10,14) \n",
    "\n",
    "ax.legend(title='Average phrase',bbox_to_anchor=(1.02, 1),handles=legend_list, loc='upper left',borderaxespad=0, fontsize=12, title_fontsize=14)\n",
    "\n",
    "x_text = 'PCA1: From phrase that include a name to \\\" Hey \\\" '\n",
    "plt.xlabel(x_text, ha='center', labelpad=35, fontsize=14)\n",
    "an1 = plt.annotate('+', xy=(0.02, -0.08), xycoords='axes fraction', xytext=(1, -0.08), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an2 = plt.annotate('-', xy=(-0.02, -0.08), xycoords=an1, fontsize=15)\n",
    "\n",
    "y_text = 'PCA2: From phrase that include \"yeah\\\" to \\\" Hi \\\"'\n",
    "plt.ylabel(y_text, ha='center', labelpad=30, fontsize=14)\n",
    "an3 = plt.annotate('+', xy=(-0.06, -0.02), xycoords='axes fraction', xytext=(-0.06, 1), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an4 = plt.annotate('-', xy=(-0.06, -0.04), xycoords=an3, fontsize=15)\n",
    "\n",
    "plt.savefig('PCA1_2_FA.png',bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52a6366",
   "metadata": {},
   "source": [
    "#### Average position (PCA1 vs PCA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea434b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "chandler =df[df['Person'].str.contains('Chandler')]\n",
    "chandler_mean_pca1_index = chandler['PCA1'].mean()\n",
    "chandler_mean_pca2_index = chandler['PCA2'].mean()\n",
    "\n",
    "joey =df[df['Person'].str.contains('Joey')]\n",
    "joey_mean_pca1_index = joey['PCA1'].mean()\n",
    "joey_mean_pca2_index = joey['PCA2'].mean()\n",
    "\n",
    "monica =df[df['Person'].str.contains('Monica')]\n",
    "monica_mean_pca1_index = monica['PCA1'].mean()\n",
    "monica_mean_pca2_index = monica['PCA2'].mean()\n",
    "\n",
    "ross =df[df['Person'].str.contains('Ross')]\n",
    "ross_mean_pca1_index = ross['PCA1'].mean()\n",
    "ross_mean_pca2_index = ross['PCA2'].mean()\n",
    "\n",
    "rachel =df[df['Person'].str.contains('Rachel')]\n",
    "rachel_mean_pca1_index = rachel['PCA1'].mean()\n",
    "rachel_mean_pca2_index = rachel['PCA2'].mean()\n",
    "\n",
    "phoebe =df[df['Person'].str.contains('Phoebe')]\n",
    "phoebe_mean_pca1_index = phoebe['PCA1'].mean()\n",
    "phoebe_mean_pca2_index = phoebe['PCA2'].mean()\n",
    "\n",
    "text = [df['Said'][closest_pt_idx[i]] for i in range(num_clusters)]\n",
    "text2 = [ '\\n'.join(wrap(l, 40)) for l in text]\n",
    "\n",
    "colors = sns.color_palette('tab20', 10)\n",
    "ind_col_map = {x:y for x, y in zip(df['Cluster'].unique(),colors)}\n",
    "ind_col_map = dict(sorted(ind_col_map.items()))\n",
    "\n",
    "\n",
    "key_order = [i[0] for i in centroid_list]\n",
    "\n",
    "df2 = X.values\n",
    "\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for i in u_labels:\n",
    "    ax.scatter(df2[label == i , 0] , df2[label == i , 1] ,color=ind_col_map[i],  label = i, alpha= 0.25)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "legend_list = []\n",
    "for key in key_order:\n",
    "    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "\n",
    "#ax.legend(title='Average phrase',bbox_to_anchor=(1.02, 1),handles=legend_list, loc='upper left',borderaxespad=0, fontsize=11, title_fontsize=13)\n",
    "\n",
    "\n",
    "plt.annotate('Chandler', (chandler_mean_pca1_index,chandler_mean_pca2_index), xytext=(10,10),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"), fontsize=16)\n",
    "\n",
    "plt.annotate('Joey', (joey_mean_pca1_index, joey_mean_pca2_index), xytext=(10,10),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Monica', (monica_mean_pca1_index, monica_mean_pca2_index), xytext=(10,10),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Ross', (ross_mean_pca1_index ,ross_mean_pca2_index ), xytext=(10,2),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Rachel', (rachel_mean_pca1_index,rachel_mean_pca2_index), xytext=(10,-2),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "plt.annotate('Phoebe', (phoebe_mean_pca1_index, phoebe_mean_pca2_index), xytext=(10,11),\n",
    "             textcoords='offset points', arrowprops=dict(arrowstyle=\"->\"),fontsize=16)\n",
    "\n",
    "\n",
    "plt.xlim(-1,2)\n",
    "plt.ylim(-0.6,0.75)\n",
    "plt.title('Average position for each character')\n",
    "\n",
    "x_text = 'PCA1: From phrase that include a name to \\\" Hey \\\" '\n",
    "plt.xlabel(x_text, ha='center', labelpad=20, fontsize=14)\n",
    "\n",
    "y_text = 'PCA2: From phrase that include \"yeah\\\" to \\\" Hi \\\"'\n",
    "plt.ylabel(y_text, ha='center', labelpad=20, fontsize=14)\n",
    "\n",
    "plt.savefig('average position FA.png',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9f917",
   "metadata": {},
   "source": [
    "### PCA3 vs PCA4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10\n",
    "X = df.loc[:,'PCA3':'PCA4']\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=num_clusters, \n",
    "    init='k-means++', \n",
    "    max_iter=100, \n",
    "    n_init=50)\n",
    "\n",
    "\n",
    "label = kmeans.fit_predict(X)\n",
    "df['Cluster']= label\n",
    "df2 = X.values\n",
    "\n",
    "closest_pt_idx = []\n",
    "for iclust in range(kmeans.n_clusters):\n",
    "    cluster_pts = df2[kmeans.labels_ == iclust]\n",
    "    cluster_pts_indices = np.where(kmeans.labels_ == iclust)[0]\n",
    "    cluster_cen = kmeans.cluster_centers_[iclust]\n",
    "    min_idx = np.argmin([euclidean(df2[idx], cluster_cen) for idx in cluster_pts_indices])\n",
    "    closest_pt_idx.append(cluster_pts_indices[min_idx])\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "centroid_list = []\n",
    "for i in np.arange(len(centroids)):\n",
    "    liste= [i, centroids[i,0], centroids[i,1]]\n",
    "    centroid_list.append(liste)\n",
    "\n",
    "centroid_list = sorted(centroid_list, key=itemgetter(1))\n",
    "\n",
    "\n",
    "u_labels = np.unique(label)\n",
    "text = [df['Said'][closest_pt_idx[i]] for i in range(num_clusters)]\n",
    "text2 = [ '\\n'.join(wrap(l, 40)) for l in text]\n",
    "\n",
    "\n",
    "colors = sns.color_palette('tab20', 10)\n",
    "ind_col_map = {x:y for x, y in zip(df['Cluster'].unique(),colors)}\n",
    "ind_col_map = dict(sorted(ind_col_map.items()))\n",
    "\n",
    "key_order = [i[0] for i in centroid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43135f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (13,9))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in u_labels:\n",
    "    ax.scatter(df2[label == i , 0] , df2[label == i , 1] ,color=ind_col_map[i],  label = i, alpha= 0.25)\n",
    "ax.scatter(centroids[:,0] , centroids[:,1] , s = 20, color = 'k')\n",
    "\n",
    "legend_list = []\n",
    "for key in key_order:\n",
    "    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "    \n",
    "plt.xlim(-10,13)\n",
    "plt.ylim(-10,14) \n",
    "\n",
    "ax.legend(title='Average phrase',bbox_to_anchor=(1.02, 1),handles=legend_list, loc='upper left',borderaxespad=0, fontsize=12, title_fontsize=14)\n",
    "x_text = 'PCA3: From phrase that include a name \\n to phrase that express the willingness to help and support someone'\n",
    "plt.xlabel(x_text, ha='center', labelpad=35, fontsize=14)\n",
    "an1 = plt.annotate('+', xy=(0.02, -0.08), xycoords='axes fraction', xytext=(1, -0.08), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an2 = plt.annotate('-', xy=(-0.02, -0.08), xycoords=an1, fontsize=15)\n",
    "\n",
    "y_text = 'PCA4: From phrase that include \\\"what \\\" or  \\\" oh my God\\\" \\n to phrase about relationship and with name'\n",
    "plt.ylabel(y_text, ha='center', labelpad=35, fontsize=14)\n",
    "an3 = plt.annotate('+', xy=(-0.06, -0.02), xycoords='axes fraction', xytext=(-0.06, 1), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an4 = plt.annotate('-', xy=(-0.06, -0.04), xycoords=an3, fontsize=15)\n",
    "plt.savefig('PCA3_4_FA.png',bbox_inches='tight')\n",
    "plt.show()             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36b575",
   "metadata": {},
   "source": [
    "### PCA5 vs PCA6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd448f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10\n",
    "X = df.loc[:,'PCA5':'PCA6']\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=num_clusters, \n",
    "    init='k-means++', \n",
    "    max_iter=100, \n",
    "    n_init=50)\n",
    "\n",
    "\n",
    "label = kmeans.fit_predict(X)\n",
    "df['Cluster']= label\n",
    "df2 = X.values\n",
    "\n",
    "closest_pt_idx = []\n",
    "for iclust in range(kmeans.n_clusters):\n",
    "    cluster_pts = df2[kmeans.labels_ == iclust]\n",
    "    cluster_pts_indices = np.where(kmeans.labels_ == iclust)[0]\n",
    "    cluster_cen = kmeans.cluster_centers_[iclust]\n",
    "    min_idx = np.argmin([euclidean(df2[idx], cluster_cen) for idx in cluster_pts_indices])\n",
    "    closest_pt_idx.append(cluster_pts_indices[min_idx])\n",
    "    \n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "centroid_list = []\n",
    "for i in np.arange(len(centroids)):\n",
    "    liste= [i, centroids[i,0], centroids[i,1]]\n",
    "    centroid_list.append(liste)\n",
    "\n",
    "\n",
    "centroid_list = sorted(centroid_list, key=itemgetter(1))\n",
    "\n",
    "\n",
    "u_labels = np.unique(label)\n",
    "text = [df['Said'][closest_pt_idx[i]] for i in range(num_clusters)]\n",
    "text2 = [ '\\n'.join(wrap(l, 40)) for l in text]\n",
    "\n",
    "\n",
    "colors = sns.color_palette('tab20', 10)\n",
    "ind_col_map = {x:y for x, y in zip(df['Cluster'].unique(),colors)}\n",
    "ind_col_map = dict(sorted(ind_col_map.items()))\n",
    "\n",
    "key_order = [i[0] for i in centroid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (13,9))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in u_labels:\n",
    "    ax.scatter(df2[label == i , 0] , df2[label == i , 1] ,color=ind_col_map[i],  label = i, alpha= 0.25)\n",
    "ax.scatter(centroids[:,0] , centroids[:,1] , s = 20, color = 'k')\n",
    "#legend_list = []\n",
    "#for key in ind_col_map.keys():\n",
    "#    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "legend_list = []\n",
    "for key in key_order:\n",
    "    legend_list.append(mpatches.Patch(color=ind_col_map[key],label=text2[key]))\n",
    "    \n",
    "plt.xlim(-10,13)\n",
    "plt.ylim(-10,14) \n",
    "\n",
    "ax.legend(title='Average phrase',bbox_to_anchor=(1.02, 1),handles=legend_list, loc='upper left',borderaxespad=0, fontsize=12, title_fontsize=14)\n",
    "x_text = 'PCA5: From phrase about character relationships to phrase that include agreement'\n",
    "plt.xlabel(x_text, ha='center', labelpad=35, fontsize=14)\n",
    "an1 = plt.annotate('+', xy=(0.02, -0.08), xycoords='axes fraction', xytext=(1, -0.08), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an2 = plt.annotate('-', xy=(-0.02, -0.08), xycoords=an1, fontsize=15)\n",
    "\n",
    "\n",
    "y_text = 'PCA6: From phrase that question a name \\n to phrase about marriage and proposal'\n",
    "plt.ylabel(y_text, ha='center', labelpad=35, fontsize=14)\n",
    "an3 = plt.annotate('+', xy=(-0.06, -0.02), xycoords='axes fraction', xytext=(-0.06, 1), arrowprops=dict(arrowstyle=\"<-\", color='lightgray'))\n",
    "an4 = plt.annotate('-', xy=(-0.06, -0.04), xycoords=an3, fontsize=15)\n",
    "plt.savefig('PCA5_6_FA.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34a3ad4",
   "metadata": {},
   "source": [
    "## Part2: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2a62d",
   "metadata": {},
   "source": [
    "#### ROC-AU-SCORE and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ffff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def logistic_function(dataset, number_pca):\n",
    "    pca = 'PCA'+str(i)\n",
    "    X = df.loc[:,'PCA1':pca]\n",
    "    X = scaled(X)\n",
    "    y = integer_encoded\n",
    "    y = np.squeeze(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state = 0)\n",
    "    y_train, y_test =  np.squeeze(y_train),  np.squeeze(y_test)\n",
    "\n",
    "    model = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_return = roc_auc_score(y_test, model.decision_function(X_test), multi_class='ovr')\n",
    "    #roc_return = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovo')\n",
    "    return roc_return\n",
    "\n",
    "\n",
    "def logistic_function_accuracy(dataset, number_pca):\n",
    "    pca = 'PCA'+str(i)\n",
    "    X = df.loc[:,'PCA1':pca]\n",
    "    X = scaled(X)\n",
    "    y = integer_encoded\n",
    "    y = np.squeeze(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state = 0)\n",
    "    y_train, y_test =  np.squeeze(y_train),  np.squeeze(y_test)\n",
    "\n",
    "    model = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def scaled(X):\n",
    "    stand = X.std(axis=0)\n",
    "    min_col = X.min(axis=0)\n",
    "    X = X.values\n",
    "    min_col = X.min(axis=1)\n",
    "    for pca in range(len(X[0,:])):\n",
    "        for row in range(len(X[:,0])):\n",
    "            X[row,pca] = (X[row,pca]-min_col[pca])/stand[pca]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1ff87",
   "metadata": {},
   "source": [
    "#### Creation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phoebe = df.loc[df['Person']== 'Phoebe']\n",
    "\n",
    "#Ross = df.loc[df['Person']== 'Ross']\n",
    "#df = pd.concat([Ross, Phoebe], ignore_index=True)\n",
    "\n",
    "Chandler = df.loc[df['Person']== 'Chandler']\n",
    "df = pd.concat([Chandler, Phoebe], ignore_index=True)\n",
    "\n",
    "print(df.pivot_table(index = ['Person'], aggfunc ='size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = df['Person']\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print('integer_encoded: ',integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc = []\n",
    "for i in range(2,301,1):\n",
    "    print('process until PCA',i)\n",
    "    roc.append(logistic_function(df, i))\n",
    "    print('done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd76098",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('array_Ross_Phoebe.npy', roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_CP = np.load('array_Chandler_Phoebe.npy')\n",
    "array_RP = np.load('array_Ross_Phoebe.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73617a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2,301)\n",
    "y1 = np.asarray(array_CP)\n",
    "y2 = np.asarray(array_RP)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "line1, = ax.plot(x, y1, '#9467bd', label='Phoebe vs Chandler')\n",
    "line2, = ax.plot(x, y2, '#17becf', label='Phoebe vs Ross')\n",
    "plt.ylim(0.51,0.8)\n",
    "ax.legend(handles=[line1, line2], loc = 'lower right')\n",
    "plt.xlabel('Number of PCA')\n",
    "plt.ylabel('AUC')\n",
    "plt.savefig('Friends_auc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea69f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(2,301,1):\n",
    "    print('process until PCA',i)\n",
    "    acc.append(logistic_function_accuracy(df, i))\n",
    "    print('done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('accuracy_Chandler_Phoebe.npy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d7948",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_CP = np.load('accuracy_Chandler_Phoebe.npy')\n",
    "accuracy_RP = np.load('accuracy_Ross_Phoebe.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2,301)\n",
    "y1 = np.asarray(accuracy_CP)\n",
    "y2 = np.asarray(accuracy_RP)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.ylim(0.51,0.8) \n",
    "\n",
    "line1, = ax.plot(x, y1, '#9467bd', label='Phoebe vs Chandler')\n",
    "line2, = ax.plot(x, y2, '#17becf', label='Phoebe vs Ross')\n",
    "ax.legend(handles=[line1, line2], loc = 'lower right')\n",
    "plt.xlabel('Number of PCA')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Friends_accuracy.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7204f927",
   "metadata": {},
   "source": [
    "## Part 3: Heat table and graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29645cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Creation of the binome\n",
    "personnes = ['Rachel', 'Ross', 'Joey', 'Monica', 'Phoebe', 'Chandler']\n",
    "couples = list(itertools.combinations(personnes, 2))\n",
    "\n",
    "for couple in couples:\n",
    "    print(couple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1332545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, perso1, perso2):\n",
    "    character1 =  dataset.loc[dataset['Person']== perso1]\n",
    "    character2 =  dataset.loc[dataset['Person']== perso2]\n",
    "    df = pd.concat([character1, character2], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "roc =[]\n",
    "coef_matrix = np.zeros((len(couples),300))\n",
    "model_intercept = np.zeros(len(couples))\n",
    "i=0\n",
    "for couple in couples:\n",
    "    print(str(couple[0]), str(couple[1]))\n",
    "    df_t = create_dataset(df, str(couple[0]), str(couple[1]))\n",
    "\n",
    "    data = df_t['Person']\n",
    "    values = array(data)\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    y = integer_encoded\n",
    "    y = np.squeeze(y)\n",
    "    \n",
    "    X = df_t.loc[:,'PCA1':'PCA300']\n",
    "    stand = X.std(axis=0)\n",
    "    mean_col = X.mean(axis=0)\n",
    "    X = X.values\n",
    "\n",
    "    for pca in range(len(X[0,:])):\n",
    "        for row in range(len(X[:,0])):\n",
    "            X[row,pca] = (X[row,pca]-mean_col[pca])/stand[pca]\n",
    "    \n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state = 0)\n",
    "    y_train, y_test =  np.squeeze(y_train),  np.squeeze(y_test)\n",
    "\n",
    "    model = LogisticRegression(solver='lbfgs').fit(X_train, y_train)\n",
    "\n",
    "    coef = model.coef_\n",
    "    coef_matrix[i]= coef\n",
    "    intercept=model.intercept_\n",
    "    model_intercept[i] = intercept[0]\n",
    "    classes=model.classes_\n",
    "    \n",
    "    #AUC\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_score = roc_auc_score(y_test, model.decision_function(X_test), multi_class='ovr')\n",
    "    temp = [str(couple[0]), str(couple[1]), roc_score]\n",
    "    roc.append(temp)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "sorted(roc, key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for couple in couples:\n",
    "    temp = str(couple[0])+ ' and ' +str(couple[1])\n",
    "    data.append(temp)\n",
    "column_names = [f'PCA{i}' for i in range(1, 301)]\n",
    "df_matrix = pd.DataFrame(coef_matrix, columns=column_names)\n",
    "df_matrix['Pairs'] = data\n",
    "#df_matrix.to_pickle('C:/Users/amaca253/Desktop/Friends-Friends-Language-Analysis/BBT/coef_matrix_Friends.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909836a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = pd.read_pickle('C:/Users/amaca253/Desktop/Friends-Friends-Language-Analysis/BBT/coef_matrix_Friends.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44eef35",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''Here we would like to create a dataset such that we read each row\n",
    " will take the absolute value of the values and save the 10st values in a \n",
    " matrix, and the values of the te corresponding pca in a list'''\n",
    "df_subset = df_matrix.loc[:, 'PCA1':'PCA300']\n",
    "data = np.zeros((len(df_subset),10))\n",
    "\n",
    "text=[]\n",
    "for row in np.arange(len(df_matrix)):\n",
    "    selected_row = np.abs(df_subset.iloc[row])\n",
    "    top_10_columns = selected_row.nlargest(10)\n",
    "    data[row] =df_subset.loc[row][top_10_columns.index]\n",
    "    text.append(top_10_columns.index)\n",
    "\n",
    "\n",
    "column_names = [f'Column{i}' for i in range(1, 11)]\n",
    "df2 = pd.DataFrame(data, columns=column_names)\n",
    "df2['Pairs']= df_matrix['Pairs']\n",
    "\n",
    "\n",
    "# Here we want to sort the value of the 1st column\n",
    "df2 = df2.sort_values('Column1',ignore_index=True)\n",
    "\n",
    "data2 = df2.loc[:, 'Column1':'Column10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we create a list that will take the \n",
    "data_list = []\n",
    "for i in np.arange(len(data)):\n",
    "    list_10 = []\n",
    "    for j in np.arange(len(data[0,:])):\n",
    "        list_temp = [data[i,j], text[i][j]] # we associate each cell to the corresponding PCA index before the sorting\n",
    "        list_10.append(list_temp)\n",
    "    data_list.append(list_10)\n",
    "\n",
    "\n",
    "sort_list = sorted(data_list, key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10, 6)) \n",
    "cmap= sns.diverging_palette(220, 20, as_cmap=True)\n",
    "maximum = data2['Column1'].abs().max()\n",
    "heatmap = sns.heatmap(data2, yticklabels=df2['Pairs'], xticklabels=[], linewidths=.5, ax=ax, cmap=cmap, vmin=-maximum, vmax=maximum)\n",
    "\n",
    "# Annotate each cell with the corresponding PCA label\n",
    "for i in range(len(df_subset)):\n",
    "    for j in range(10):\n",
    "        cell_label = sort_list[i][j][1]\n",
    "        ax.text(j + 0.5, i + 0.5, cell_label, ha='center', va='center', fontsize=8, color= 'white', fontweight = 'bold')\n",
    "#plt.savefig('heatmap_friends_abs_top10.png',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_names(names):\n",
    "    name_list = names.split(\" and \")\n",
    "    name_list = [name.strip() for name in name_list]\n",
    "    return name_list\n",
    "\n",
    "\n",
    "pair = []\n",
    "for i in np.arange(len(df2)):\n",
    "        couple = df2['Pairs'][i]\n",
    "        couple = split_names(couple)\n",
    "        temp = (couple[0], couple[1])\n",
    "        temp = 'P('+ str(couple[0])+ '|' + str(couple[0]) + ' or ' + str(couple[1]) + ')' \n",
    "        pair.append(temp)\n",
    "        print(temp)\n",
    "\n",
    "        \n",
    "df2['Pairs'] = pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fff8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6)) \n",
    "cmap= sns.diverging_palette(220, 20, as_cmap=True)\n",
    "maximum = data2['Column1'].abs().max()\n",
    "heatmap = sns.heatmap(data2, yticklabels=df2['Pairs'], xticklabels=[], linewidths=.5, ax=ax, cmap=cmap, vmin=-maximum, vmax=maximum)\n",
    "\n",
    "# Annotate each cell with the corresponding PCA label\n",
    "for i in range(len(df_subset)):\n",
    "    for j in range(10):\n",
    "        cell_label = sort_list[i][j][1]\n",
    "        ax.text(j + 0.5, i + 0.5, cell_label, ha='center', va='center', fontsize=8, color= 'white', fontweight = 'bold')\n",
    "plt.savefig('heatmap_Friends_abs_top10_2.png',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def split_names(names):\n",
    "    name_list = names.split(\" and \")\n",
    "    name_list = [name.strip() for name in name_list]\n",
    "    return name_list\n",
    "\n",
    "\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "node = personnes\n",
    "G.add_nodes_from(node)\n",
    "\n",
    "coefficients={}\n",
    "edges = []\n",
    "for i in np.arange(len(df_matrix)):\n",
    "    coeff = df_matrix['PCA9'][i] #9 for friends \n",
    "    print(coeff)\n",
    "    if np.abs(coeff) <= 0.1:\n",
    "        i+=1\n",
    "    else:\n",
    "        couple = split_names(df_matrix['Pairs'][i])\n",
    "        temp = (couple[0], couple[1], coeff )\n",
    "        edges.append(temp)\n",
    "\n",
    "\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# Create lists of edges and labels for positive and negative weights\n",
    "positive_edges = [(u, v) for u, v, d in G.edges(data=True) if d['weight'] >= 0]\n",
    "negative_edges = [(u, v) for u, v, d in G.edges(data=True) if d['weight'] < 0]\n",
    "edge_labels = {(u, v): f\"{w:.2f}\" if w >= 0 else f\"{-w:.2f}\" for (u, v, w) in G.edges(data='weight')}\n",
    "\n",
    "# Draw the graph\n",
    "fig, ax = plt.subplots(figsize=(10, 8))  # Adjust the size of the plot\n",
    "pos = nx.spring_layout(G, k=3)\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, edgelist=positive_edges, node_size=2500, node_color=\"skyblue\", \n",
    "        font_size=9, arrows=True, arrowstyle= '-|>')\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, edgelist=negative_edges,node_size=2500, node_color=\"skyblue\", \n",
    "        font_size=9, arrows=True, arrowstyle= '<|-')\n",
    "        \n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "#plt.savefig(\"graphfriends.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
